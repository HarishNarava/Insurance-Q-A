{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ollama = Ollama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1:latest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(model='llama3.1:latest')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the prompt template\n",
    "template = \"\"\"Answer the question using only the provided context. Be concise and provide estimates when requested. If the context is insufficient, state that you lack enough information:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "dataframe = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'subCategory', 'question', 'answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# PRinting columns of the dataset\n",
    "print(dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing documents for FAISS \n",
    "documents = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    documents.append(Document(page_content=row[\"answer\"], metadata={\"category\": row[\"category\"], \"subCategory\": row[\"subCategory\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/3b5d6y0527b3rqt28d98y2vc0000gn/T/ipykernel_71364/20070093.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# Generating embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})  # Top 3 relevant contexts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/3b5d6y0527b3rqt28d98y2vc0000gn/T/ipykernel_71364/3423603055.py:11: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n",
      "/var/folders/6w/3b5d6y0527b3rqt28d98y2vc0000gn/T/ipykernel_71364/3423603055.py:16: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  ollama_output = llm_ollama(prompt.format(context=context, question=query))\n"
     ]
    }
   ],
   "source": [
    "# Generating answers using the model\n",
    "data = {\"question\": [], \"ground_truth\": [], \"answer_ollama\": [], \"contexts\": []}\n",
    "for index, row in dataframe.iterrows():\n",
    "    query = row[\"question\"]  # Column name for questions\n",
    "    ground_truth = row[\"answer\"]  # Column name for ground truth answers\n",
    "\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"ground_truth\"].append(ground_truth)\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "    data[\"contexts\"].append([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # Run pipeline with ollama\n",
    "    ollama_output = llm_ollama(prompt.format(context=context, question=query))\n",
    "    data[\"answer_ollama\"].append(ollama_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"reference\"] = [\" \".join(contexts) for contexts in data[\"contexts\"]]  # Combine list into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to a Dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the ground_truth column to response for compatibility with RAGAs\n",
    "dataset = dataset.rename_column(\"ground_truth\", \"response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 428/428 [03:29<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the RAG QnA with RAGAs\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.8449, 'faithfulness': 0.9168, 'context_precision': 0.9665, 'context_recall': 0.9677}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the metrics\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the average life insurance cost per month?', 'ground_truth': 'The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa.', 'answer_ollama': 'Unfortunately, I must inform you that there isn\\'t an explicit \"average\" mentioned in the context. However, we can make an educated estimate based on the provided information.\\n\\nAssuming the given example of a 26-year-old male applicant with an annual salary of Rs.7 lakh and sum assured of Rs.1 crore is somewhat representative of an average premium price, let\\'s try to calculate the estimated average life insurance cost per month for a different set of applicants.\\n\\nLet\\'s consider a few examples:\\n\\n* For a 30-year-old non-smoking male with a Rs.5 lakh annual salary, the premium might be slightly lower.\\n* For a 40-year-old non-smoking female with a Rs.10 lakh annual salary, the premium might be higher.\\n\\nTo make an educated estimate, let\\'s assume an average age of 35 years for our applicants and an average sum assured of Rs.50 lakhs (considering the initial example has a sum assured of Rs.1 crore).\\n\\nWe can use the given example as a reference point:\\n\\nFor a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh, the premium price for a sum assured of Rs.1 crore is Rs.933 per month.\\n\\nLet\\'s consider a similar scenario for our assumed average age and sum assured:\\nFor a 35-year-old non-smoking female with a Rs.10 lakh annual salary and a sum assured of Rs.50 lakhs, the premium might be lower than Rs.933 per month due to her non-smoking status and higher income.\\n\\nTo make an estimate, let\\'s assume it could be around 20-30% lower:\\n\\nRs.933 per month × 0.7 (conservative estimate: 30% lower) = approximately Rs.652 per month\\nor\\nRs.933 per month × 0.8 (moderate estimate: 20% lower) = approximately Rs.747 per month\\n\\nTaking a midpoint of these estimates:\\n\\nThe estimated average life insurance cost per month could be around **Rs.699**.\\n\\nPlease note that this is an extremely rough estimate and actual premium prices can vary widely depending on individual circumstances, insurance provider, policy type, etc.', 'contexts': ['The premium rates for term insurance plans depend on your age, gender, income, and even your smoking habits. Based on these factors, the prices differ from one applicant to another. For instance, for a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh, the premium price for a sum assured of Rs.1 crore is Rs.933 per month.', 'The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa.', 'Life insurance prices are heavily influenced by your age. As you grow older, the premium rates will increase as old age makes us more vulnerable to risks. Ideally, you should invest in a life insurance plan in your late 20s or early 30s. The ideal age varies based on the number of dependents you have. If you have a history of any critical illness in your family, it is advisable to invest in a plan as soon as possible.'], 'reference': 'The premium rates for term insurance plans depend on your age, gender, income, and even your smoking habits. Based on these factors, the prices differ from one applicant to another. For instance, for a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh, the premium price for a sum assured of Rs.1 crore is Rs.933 per month. The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa. Life insurance prices are heavily influenced by your age. As you grow older, the premium rates will increase as old age makes us more vulnerable to risks. Ideally, you should invest in a life insurance plan in your late 20s or early 30s. The ideal age varies based on the number of dependents you have. If you have a history of any critical illness in your family, it is advisable to invest in a plan as soon as possible.'}\n"
     ]
    }
   ],
   "source": [
    "# Displaying the first row of stored data\n",
    "print({key: value[0] for key, value in data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data to CSV\n",
    "output_df = pd.DataFrame(data)\n",
    "output_df.to_csv(\"genans1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama Output: To avoid paying late fees in life insurance, consider the following options:\n",
      "\n",
      "1. **Select auto-debit option**: This way, you'll never miss out on premium payments, and your account will be automatically debited on the due date.\n",
      "2. **Select reminder option before premium payment date**: Set reminders a few days or weeks before the payment is due to ensure you have enough time to make the payment.\n",
      "3. **Keep track of premium payment reminders**: Regularly check your email or mobile notifications for reminders, and make payments promptly.\n",
      "4. **Opt for yearly premium payment instead of monthly payments**: This approach can help you avoid missing out on regular payments and reduce the risk of late fees.\n",
      "\n",
      "By implementing these strategies, you can minimize the likelihood of incurring late fees on your life insurance premiums.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ollama Output: {ollama_output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
