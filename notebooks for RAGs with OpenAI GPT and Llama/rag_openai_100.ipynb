{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm_gpt = OpenAI(temperature=0.5, max_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "template = \"\"\"Answer the question using only the provided context. Be concise and provide estimates when requested. If the context is insufficient, state that you lack enough information:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\Harish\\AppData\\Local\\Temp\\ipykernel_25124\\933837871.py:2: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  dataframe = pd.read_csv(\"D:\\LLMs\\FProject_2\\data\\insurance.csv\")\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'subCategory', 'question', 'answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing documents for FAISS\n",
    "documents = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    documents.append(Document(page_content=row[\"answer\"], metadata={\"category\": row[\"category\"], \"subCategory\": row[\"subCategory\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})  # Top 3 relevant contexts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating answers using the model\n",
    "data = {\"question\": [], \"ground_truth\": [], \"answer_gpt\": [], \"contexts\": []}\n",
    "for index, row in dataframe.iterrows():\n",
    "    query = row[\"question\"]  # Column name for questions\n",
    "    ground_truth = row[\"answer\"]  # Column name for ground truth answers\n",
    "\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"ground_truth\"].append(ground_truth)\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "    data[\"contexts\"].append([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # Run pipeline with GPT\n",
    "    gpt_output = llm_gpt(prompt.format(context=context, question=query))\n",
    "    data[\"answer_gpt\"].append(gpt_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"reference\"] = [\" \".join(contexts) for contexts in data[\"contexts\"]]  # Combine list into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to a Dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the ground_truth column to response for compatibility with RAGAs\n",
    "dataset = dataset.rename_column(\"ground_truth\", \"response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 428/428 [04:04<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with RAGAs\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation result for the RAG system using OpenAI GPT:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.8277, 'faithfulness': 0.9147, 'context_precision': 0.9688, 'context_recall': 0.9695}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The evaluation result for the RAG system using OpenAI GPT:\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the average life insurance cost per month?', 'ground_truth': 'The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa.', 'answer_gpt': '\\nThe average life insurance cost per month can vary greatly depending on various factors such as age, gender, income, smoking habits, type of policy, and sum assured. However, for a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh and a sum assured of Rs.1 crore, the average premium price for a term insurance plan is Rs.933 per month. It is important to note that the cost of a life insurance policy can increase with age and a higher sum assured will also result in a higher premium.', 'contexts': ['The premium rates for term insurance plans depend on your age, gender, income, and even your smoking habits. Based on these factors, the prices differ from one applicant to another. For instance, for a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh, the premium price for a sum assured of Rs.1 crore is Rs.933 per month.', 'The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa.', 'Life insurance prices are heavily influenced by your age. As you grow older, the premium rates will increase as old age makes us more vulnerable to risks. Ideally, you should invest in a life insurance plan in your late 20s or early 30s. The ideal age varies based on the number of dependents you have. If you have a history of any critical illness in your family, it is advisable to invest in a plan as soon as possible.'], 'reference': 'The premium rates for term insurance plans depend on your age, gender, income, and even your smoking habits. Based on these factors, the prices differ from one applicant to another. For instance, for a 26-year-old male applicant who smokes with an annual salary of Rs.7 lakh, the premium price for a sum assured of Rs.1 crore is Rs.933 per month. The cost of a life insurance policy depends on the type of policy you own. Term plans are generally cheaper in nature as it only offers death benefit with no profits or returns. Traditional plans and unit-linked plans tend to cost more as they offer a wide range of benefits. The cost also depends on the sum assured i.e. a higher sum assured will cost you more and vice versa. Life insurance prices are heavily influenced by your age. As you grow older, the premium rates will increase as old age makes us more vulnerable to risks. Ideally, you should invest in a life insurance plan in your late 20s or early 30s. The ideal age varies based on the number of dependents you have. If you have a history of any critical illness in your family, it is advisable to invest in a plan as soon as possible.'}\n"
     ]
    }
   ],
   "source": [
    "# Display the first row of stored data\n",
    "print({key: value[0] for key, value in data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV\n",
    "output_df = pd.DataFrame(data)\n",
    "output_df.to_csv(\"ins100_gen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Output: \n",
      "You can avoid paying late fees in life insurance by selecting the auto-debit option, setting reminders before the premium payment date, keeping track of premium payment reminders, opting for yearly premium payments, and being aware of the exclusions and grace period of your policy.\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPT Output: {gpt_output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
